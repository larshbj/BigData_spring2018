{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big Data: Project Phase 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### By Tormod Alf Try Tufteland and Lars Henrik Berg-Jensen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession, Row\n",
    "import os, shutil, datetime\n",
    "from collections import Counter\n",
    "from operator import add, itemgetter\n",
    "from functools import reduce\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Spark Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master = \"local[4]\"\n",
    "appName = \"phase2\"\n",
    "conf = SparkConf().setAppName(appName).setMaster(master)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.setLogLevel(\"WARN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods for reading dataset, input tweet and saving result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def takeTrainingAndReturnList(input_path=\"data/geotweets.tsv\"):\n",
    "    rdd = sc.textFile(input_path)\n",
    "    return rdd.map(lambda x: x.split('\\t'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def takeInputAndReturnList(input_path='data/input1.txt'):\n",
    "    with open(input_path, 'r') as f:\n",
    "        input_tweet = f.readlines()\n",
    "        input_tweet_list = [i.rstrip().split(' ') for i in input_tweet]\n",
    "    return list(map(str.lower, input_tweet_list[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveResultToFile(result, output_path=\"results/output_phase2.tsv\"):\n",
    "    result_rdd = sc.parallelize(result).map(lambda x: '{}\\t{}'.format(x[0], x[1]))\n",
    "    if os.path.isdir(output_path):\n",
    "        shutil.rmtree(output_path)\n",
    "    result_rdd.coalesce(1).saveAsTextFile(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods for computing number of total tweets and tweets per place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTotalTweetCount(rdd):\n",
    "    return rdd.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Counts tweets per place and loads the result as a dictionary in the driver's memory for easy access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes a tweet count per place map\n",
    "def getTweetsPerPlaceCount(place_and_tweets):\n",
    "    tweets_per_place_count = place_and_tweets.map(lambda x: (x[0], 1)).countByKey().items()\n",
    "    return sc.parallelize(tweets_per_place_count).collectAsMap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method for counting number of tweets per place containing one of the input tweet words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For each key (place), convert the tuple value to a dictionary containing the input tweet words as keys, and their respective occurences in tweets as values. Counting the tweet words per place, and then combining the result by key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input: tweets_by_city rdd: [('place1', ['word1', 'word2', 'word3'...]), ...] and input tweet list\n",
    "#Output: Tuples with place as key and a dictionary containing count for every word from input tweet\n",
    "def getTweetWithWordByCityCount(tweets_by_city, input_tweet_list):\n",
    "    # Helper methods used in combineByKey\n",
    "    def addIfWordInTweet(word, value, tweet_list):\n",
    "        if word in tweet_list:\n",
    "            value += 1\n",
    "        return value\n",
    "\n",
    "    def to_dict(tweet_list):\n",
    "        counter_dict = {k: 0 for k in input_tweet_list}\n",
    "        return counter_dict\n",
    "\n",
    "    def add(counter_dict, tweet_list):\n",
    "        return {k: addIfWordInTweet(k, v, tweet_list) for k, v in counter_dict.items()}\n",
    "\n",
    "    def merge(dict1, dict2):\n",
    "        new = {**dict1, **dict1}\n",
    "        return new\n",
    "\n",
    "    counted_tweets_with_word_by_city = tweets_by_city.combineByKey(to_dict, add, merge)\n",
    "    return counted_tweets_with_word_by_city"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method for computing the probability for a single place, based on the Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate probability for a single place\n",
    "def calculateProbability(place, data_dict, nr_tweets_place, total_tweet_count):\n",
    "    initial_value = nr_tweets_place / total_tweet_count\n",
    "    probability = reduce(lambda x, value: x * value / nr_tweets_place, data_dict.values(), initial_value)\n",
    "    return probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method for combining probability of all places into a new list and then sorting it in descending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate probabilities for all places and sort\n",
    "def findProbabilitiesAndSort(counted_tweets_with_word_by_city, tweet_per_place_count_map, total_tweet_count):\n",
    "    probabilities = counted_tweets_with_word_by_city\\\n",
    "            .map(lambda x: (x[0], calculateProbability(x[0], x[1], tweet_per_place_count_map[x[0]], total_tweet_count)))\n",
    "    sorted_probabilities = sorted(probabilities.collect(), key=lambda x: x[1], reverse=True)\n",
    "    return sorted_probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrapper function to make the estimations for each place and then returns the most probable place(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapper method and outputs the most probable place(s)\n",
    "def estimatePlaces(rdd_list, input_tweet_list):\n",
    "    place_and_tweets = rdd_list.map(lambda x: (x[4], x[10]))\\\n",
    "                        .mapValues(lambda x: x.split(' '))\n",
    "\n",
    "    total_tweet_count = getTotalTweetCount(rdd_list)\n",
    "    tweet_per_place_count_map = getTweetsPerPlaceCount(place_and_tweets)\n",
    "    tweets_by_city = place_and_tweets.map(lambda x: (x[0], list(map(str.lower, x[1]))))\n",
    "    counted_tweets_with_word_by_city = getTweetWithWordByCityCount(tweets_by_city, input_tweet_list)\n",
    "    sorted_probabilities = findProbabilitiesAndSort(counted_tweets_with_word_by_city, tweet_per_place_count_map, total_tweet_count)\n",
    "\n",
    "    result = []\n",
    "    top_probability = sorted_probabilities[0][1]\n",
    "    if top_probability != 0:\n",
    "        for place in sorted_probabilities:\n",
    "            if place[1] == top_probability:\n",
    "                result.append(place)\n",
    "            else: break\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch training data and input tweet, estimate the places and save the result to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_list = takeTrainingAndReturnList()\n",
    "input_tweet_list = takeInputAndReturnList()\n",
    "places = estimatePlaces(rdd_list, input_tweet_list)\n",
    "saveResultToFile(places)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (BigData_spring2018)",
   "language": "python",
   "name": "bigdata_spring2018"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
